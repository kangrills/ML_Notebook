{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Artificial_neural_network.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMzGJLxUZpNPV/HUywvj/Gy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4lWFOBBdJRc2"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["df=pd.read_csv(r'https://github.com/YBI-Foundation/Dataset/raw/main/Diabetes.csv')"],"metadata":{"id":"t1jfCkVpJWg9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"3Qx7_5AZJiWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"iNgtWHuzJpw5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe()"],"metadata":{"id":"2_WoVCKnJxDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"s4YiOW4mKKhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X=df[['pregnancies', 'glucose', 'diastolic', 'triceps', 'insulin', 'bmi',\n","       'dpf', 'age']]\n","X.shape\n","#X=df.drop('diabetes',axis=1)"],"metadata":{"id":"31LjeFiaKSGp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y=df['diabetes']"],"metadata":{"id":"xKxaOgiJKkVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.shape, y.shape"],"metadata":{"id":"BjYFZ9ltLDjP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"jtKHZOxmMDjq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sc=StandardScaler()"],"metadata":{"id":"NPBLFMtZMT5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sc.fit(X)"],"metadata":{"id":"_0yEhrXtMZR8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X=sc.transform(X)"],"metadata":{"id":"0YFH7sXdMbOA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#X=sc.fit_transform(X) can also be used\n","X"],"metadata":{"id":"iM0qPLx5MfJv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense\n","model= Sequential()\n","# sequential for every layer write each line of code\n","#for dense connection each neurons are connected to previous all neuron\n","model.add(Dense(9, input_dim=8, activation=\"relu\"))\n","#9 is for 8 feature + bias, only in first line initialize input_dim= 8 features for no of features\n","model.add(Dense(12, activation ='relu'))\n","# 12 depends on you for no of neurons\n","model.add(Dense(14, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","# for binary decison at the last need only 1 neuron binary always use sigmoid\n"],"metadata":{"id":"-RRG70hFNRs4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"5rK1bDSxUWtp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","# for backward propogation loss is error to be calculated using  binary problem binary_crossentropy\n","# optimizer to minimize error using Gradient descent function or adam "],"metadata":{"id":"pdN6v6XoQI3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"q5NMSO4QQ_Y2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 398 weights need to be calculated, therefore need more data. As data is not that large so solution is EPOCHS"],"metadata":{"id":"jOCcG42vUfRt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(X,y,epochs=100, batch_size=100)\n","# epochs: no of times data move in a loop\n","# optimizer will run only after 100 batch size"],"metadata":{"id":"0VXRnK-sWD7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score=model.evaluate(X,y,verbose=0)\n","print(score)\n","# loss and accuracy"],"metadata":{"id":"ShrgHQ-dW4-w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred=model.predict(X)"],"metadata":{"id":"uPO0JoFqZcDD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred[:10]"],"metadata":{"id":"2TwMGWdpZxPv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"zeNQPU_dZ0Ae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred=y_pred.round()\n","#round float to integer 0,1"],"metadata":{"id":"OPMRcF0sZ4iF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred"],"metadata":{"id":"v-WbE7aqZ7YQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n"],"metadata":{"id":"VUKAy4G6aATt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confusion_matrix(y,y_pred)"],"metadata":{"id":"61v2HGEmaRSB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y,y_pred))"],"metadata":{"id":"iTFgLCHLaUb5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for precision and recall used confusion matrix"],"metadata":{"id":"Y4GqQdEgaga_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"23t927lKadoa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["IRIS"],"metadata":{"id":"SpIMsUxyx38A"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import datasets"],"metadata":{"id":"GFlY7FvVyl2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris=datasets.load_iris()"],"metadata":{"id":"HJdrN4xAytMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris.DESCR"],"metadata":{"id":"woDRjewCzEGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(iris.DESCR)"],"metadata":{"id":"hNuuI49oyxyN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris\n","# gives the documentation in the datasets. we can also use boston for boston dataset"],"metadata":{"id":"XL08KMwqy32b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X=iris.data\n","X"],"metadata":{"id":"Q5P_6kfYzO0S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y=iris.target"],"metadata":{"id":"WmcW3brFz0Kg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.shape, y.shape"],"metadata":{"id":"LUaawienz3H_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# in ann always do the scaling to solve scaling problem"],"metadata":{"id":"InaQPCSQ0CK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# in regression we remove the outliar or take log before fitting"],"metadata":{"id":"-HxfchBx0T6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"8ThO0pLl0fkJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# in preprocessing we use .fit_transform() for ann while in sklearn  we use .fit .pred\n","sc=StandardScaler()"],"metadata":{"id":"3nMA8EXh0lFK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sc.fit(X)"],"metadata":{"id":"zo3W5Yw_09Nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X=sc.transform(X)\n","X"],"metadata":{"id":"2XaRdCtH0_7E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","# encoded target variables as Label\n","# if target variable is itself numerical scale need not to be encodedd as label"],"metadata":{"id":"KXXmw03V17IZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["le=LabelEncoder()"],"metadata":{"id":"QWUKh7oz25n_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y=le.fit_transform(y)"],"metadata":{"id":"TlDBcEDq3gRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"id":"M0pMalrZ383N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y=pd.get_dummies(y)\n","#always need to convert dummy variable for more than 2 class problem in ann"],"metadata":{"id":"Akvvyhd63_JY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"id":"fAggymGl4GsB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.shape, y.shape"],"metadata":{"id":"ru0xcKeZ4Hp0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense\n","model= Sequential()\n","# sequential for every layer write each line of code\n","#for dense connection each neurons are connected to previous all neuron\n","model.add(Dense(5, input_dim=4, activation=\"relu\"))\n","#5 is for 4 feature + bias, only in first line initialize input_dim= 4 features for no of features\n","model.add(Dense(12, activation ='relu'))\n","# 12 depends on you for no of neurons\n","model.add(Dense(14, activation='relu'))\n","model.add(Dense(3, activation='softmax'))\n","#  3 as 3 class problem\n","#Since 3 class problem use softmax, softmax can also be used for 1 but sigmoid is better"],"metadata":{"id":"ZIfjPFra7O_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","#optimizer:sjd, gradient discent"],"metadata":{"id":"9vlUNe8-7210"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(X,y,epochs=500,batch_size=25)"],"metadata":{"id":"N1dK4AnT-o5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score=model.evaluate(X,y,verbose=0)"],"metadata":{"id":"oKdUSBzd-1wK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(score)"],"metadata":{"id":"UzzPzIu8_vJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predict=model.predict(X)"],"metadata":{"id":"HqH-Cl5J_xuc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predict.shape"],"metadata":{"id":"zlCdo4-X_3vv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"id":"Ut6Lr4y6_7Ir"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred=model.predict(X)"],"metadata":{"id":"ZUhnUFYx__4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred=y_pred.argmax(axis=-1)\n","y_pred.shape\n","#keep max and drop else - convert into a single row vector"],"metadata":{"id":"oev8SYAtADW7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y=iris.target"],"metadata":{"id":"k2OF1Up1AIU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred.shape"],"metadata":{"id":"N1Srt0CFAYxz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.shape\n","from sklearn.metrics import confusion_matrix,classification_report"],"metadata":{"id":"SyZv2nHtAbEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confusion_matrix(y,y_pred)"],"metadata":{"id":"a178jthuAwnG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predict=model.predict(X)"],"metadata":{"id":"0neklGkTBkbi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predict.shape"],"metadata":{"id":"rvixtWAXBoiz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FYOJs_2aBsUb"},"execution_count":null,"outputs":[]}]}